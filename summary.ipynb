{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kepler dataset \n",
    "\n",
    "* Goal: Predict koi_disposition using all vaiables except koi_pdispositon   \n",
    "* Secondary goal: Using 'CANDIDATES' from koi_pdisposition predict which rows are most likely to become 'CONFIRMED' in koi_disposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports \n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_median(data):\n",
    "    for column in data.columns:\n",
    "        print(\"Current columns: \", column)\n",
    "        tmp = data[column].dtypes\n",
    "        \n",
    "        if tmp == 'int64' or tmp == 'float64':\n",
    "            print(\"Number of NaN: \", data[column].isna().sum())\n",
    "            print(\"Total length: \", len(data[column]))\n",
    "            median = data[column].median()\n",
    "            data[column] = data[column].fillna(median)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def create_3d_plot(data, target, figsize, class_list):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    for c, dispo, a in class_list:\n",
    "        tmp_df = data[data[target] == dispo]\n",
    "        xs = tmp_df['X']\n",
    "        ys = tmp_df['Y']\n",
    "        zs = tmp_df['Z']\n",
    "        ax.scatter(xs, ys, zs, s=50, alpha=a, edgecolors='w', c=c)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    # ax.view_init(30, 90)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import dataset \n",
    "#\n",
    "data = pd.read_csv('cumulative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_teq_err1</th>\n",
       "      <th>koi_teq_err2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>0.969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowid     kepid kepoi_name   kepler_name  koi_score  koi_teq_err1  \\\n",
       "0      1  10797460  K00752.01  Kepler-227 b      1.000           NaN   \n",
       "1      2  10797460  K00752.02  Kepler-227 c      0.969           NaN   \n",
       "2      3  10811496  K00753.01           NaN      0.000           NaN   \n",
       "3      4  10848459  K00754.01           NaN      0.000           NaN   \n",
       "4      5  10854555  K00755.01  Kepler-664 b      1.000           NaN   \n",
       "\n",
       "   koi_teq_err2  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Data cleaning \n",
    "#\n",
    "\n",
    "drop_columns = ['rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_score', 'koi_teq_err1', 'koi_teq_err2']\n",
    "data[drop_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rowid` - The data in this column is nothing more than an index.   \n",
    "`kepid` - Id for solar system.   \n",
    "`kepoi_name` - Name for solar system and planet number.  \n",
    "`kepler_name` - Name for exoplanet. NaN represents none expoplanets.   \n",
    "`koi_score` - NASA prediction score for candidate.   \n",
    "`koi_teq_err1` - Entire column is NaN.  \n",
    "`koi_teq_err2` - Entire column is NaN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(drop_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8744\n",
       "2      248\n",
       "29     230\n",
       "6       95\n",
       "31      91\n",
       "10      89\n",
       "26      42\n",
       "1       15\n",
       "8        7\n",
       "16       2\n",
       "7        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_nan = data.isna().sum(axis=1)\n",
    "rows_nan.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got 40 features, to reduce noise in the datset we remove samples that are missing more than 10 % of their feature values, which is 4 or more missing feature values. As we can see in the data above there are several samples that are missing a lot of data. If we were to just insert the median in to these missing values we would introduce noise or skew the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_nan = rows_nan[rows_nan >= 4]\n",
    "rows_nan = rows_nan.reset_index()\n",
    "data = data.drop(index = rows_nan[\"index\"].to_numpy(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FALSE POSITIVE    4552\n",
       "CONFIRMED         2292\n",
       "CANDIDATE         2163\n",
       "Name: koi_disposition, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['koi_disposition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are more interesting to keep 'CANDIDATES' and 'CONFIRMED' in the columnn `koi_disposition` because they add more value in the modeling process compared to 'FALSE POSITIVE', because it's 50% of the dataset while 'CONFIRMED' is about 25%. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns:  koi_disposition\n",
      "Current columns:  koi_pdisposition\n",
      "Current columns:  koi_fpflag_nt\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_fpflag_ss\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_fpflag_co\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_fpflag_ec\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_period\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_period_err1\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_period_err2\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_time0bk\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_time0bk_err1\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_time0bk_err2\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_impact\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_impact_err1\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_impact_err2\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_duration\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_duration_err1\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_duration_err2\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_depth\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_depth_err1\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_depth_err2\n",
      "Number of NaN:  78\n",
      "Total length:  4541\n",
      "Current columns:  koi_prad\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_prad_err1\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_prad_err2\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_teq\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_insol\n",
      "Number of NaN:  63\n",
      "Total length:  4541\n",
      "Current columns:  koi_insol_err1\n",
      "Number of NaN:  63\n",
      "Total length:  4541\n",
      "Current columns:  koi_insol_err2\n",
      "Number of NaN:  63\n",
      "Total length:  4541\n",
      "Current columns:  koi_model_snr\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_tce_plnt_num\n",
      "Number of NaN:  75\n",
      "Total length:  4541\n",
      "Current columns:  koi_tce_delivname\n",
      "Current columns:  koi_steff\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_steff_err1\n",
      "Number of NaN:  72\n",
      "Total length:  4541\n",
      "Current columns:  koi_steff_err2\n",
      "Number of NaN:  85\n",
      "Total length:  4541\n",
      "Current columns:  koi_slogg\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_slogg_err1\n",
      "Number of NaN:  72\n",
      "Total length:  4541\n",
      "Current columns:  koi_slogg_err2\n",
      "Number of NaN:  72\n",
      "Total length:  4541\n",
      "Current columns:  koi_srad\n",
      "Number of NaN:  64\n",
      "Total length:  4541\n",
      "Current columns:  koi_srad_err1\n",
      "Number of NaN:  72\n",
      "Total length:  4541\n",
      "Current columns:  koi_srad_err2\n",
      "Number of NaN:  72\n",
      "Total length:  4541\n",
      "Current columns:  ra\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  dec\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n",
      "Current columns:  koi_kepmag\n",
      "Number of NaN:  0\n",
      "Total length:  4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Seperate False Positives from Candidates and Confirmed\n",
    "# This is to run seperate Data Cleaning processes on the sets\n",
    "data_fp = data_cleaned[data_cleaned['koi_disposition'] == 'FALSE POSITIVE']\n",
    "data_cc = data_cleaned[data_cleaned['koi_disposition'] != 'FALSE POSITIVE']\n",
    "data_fp = data_fp.dropna(axis = 0) # Drop every row that contains atleast one NaN\n",
    "data_cc = fill_median(data_cc) # Fill each NaN with the median of the column\n",
    "\n",
    "# Merge the two datasets back together after cleaning\n",
    "data_merged = pd.concat([data_fp, data_cc], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data exploration \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the state changes from `koi_pdisposition` to `koi_disposition`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONFIRMED</th>\n",
       "      <th>FALSE POSITIVE</th>\n",
       "      <th>CANDIDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FALSE POSITIVE</th>\n",
       "      <td>44</td>\n",
       "      <td>4552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CANDIDATE</th>\n",
       "      <td>2248</td>\n",
       "      <td>0</td>\n",
       "      <td>2163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CONFIRMED  FALSE POSITIVE  CANDIDATE\n",
       "FALSE POSITIVE         44            4552          0\n",
       "CANDIDATE            2248               0       2163"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = data['koi_disposition'].unique()\n",
    "array = np.empty((2,3), dtype=np.int64)\n",
    "for i, c in enumerate(classes, start=0):\n",
    "    mask = (data['koi_disposition'] == c) & (data['koi_pdisposition'] == 'FALSE POSITIVE')\n",
    "    l = len(data['koi_disposition'][mask])\n",
    "    array[0, i] = l\n",
    "    \n",
    "    mask = (data['koi_disposition'] == c) & (data['koi_pdisposition'] == 'CANDIDATE')\n",
    "    l = len(data['koi_disposition'][mask])\n",
    "    array[1, i] = l\n",
    "    \n",
    "df = pd.DataFrame(array, columns=classes, index=['FALSE POSITIVE', 'CANDIDATE'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that a 44 cases went from FALSE POSITIVE to CONFIRMED. We extract those special cases to be able to separate them later in visualization.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo** Outlier removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ToDo** Check correlation between features in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Data preprocessing \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Modeling\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluation \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
